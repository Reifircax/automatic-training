{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3bc30b2fd244afebb59ec17c2426094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8eaff451261467cb335d753da33357b",
              "IPY_MODEL_3cc9e9c896154ded80b87ff24971a5e8",
              "IPY_MODEL_52dd96d97087456cba48a87b2c473d8a"
            ],
            "layout": "IPY_MODEL_418b934cddf540bb989e2ce797fd1df0"
          }
        },
        "b8eaff451261467cb335d753da33357b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc538c08b65471a80089150ddb8e2b9",
            "placeholder": "​",
            "style": "IPY_MODEL_cbfcfeb2a4384a3a846b6162f75e1df7",
            "value": "Downloading builder script: "
          }
        },
        "3cc9e9c896154ded80b87ff24971a5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded8a90ee44248f68e317fcda0903634",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46c1805f82df4228b1e8eddd1d5ef00b",
            "value": 1
          }
        },
        "52dd96d97087456cba48a87b2c473d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f3a8bc9c084e5aa3f5157311c2b188",
            "placeholder": "​",
            "style": "IPY_MODEL_7a870a47357c4286959818b62e57bcbc",
            "value": " 46.3k/? [00:00&lt;00:00, 2.13MB/s]"
          }
        },
        "418b934cddf540bb989e2ce797fd1df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc538c08b65471a80089150ddb8e2b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfcfeb2a4384a3a846b6162f75e1df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ded8a90ee44248f68e317fcda0903634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "46c1805f82df4228b1e8eddd1d5ef00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f3a8bc9c084e5aa3f5157311c2b188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a870a47357c4286959818b62e57bcbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de734d32b95473cb44e4931875b52d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85b493493e4e4562a3db355f57ebe0b1",
              "IPY_MODEL_5dc5505d11e749b196e8b5cfc42cb588",
              "IPY_MODEL_de26ae4953f44fe0b6252ae0661aaafc"
            ],
            "layout": "IPY_MODEL_23bf6c6f895b49c689497717cd98a1d1"
          }
        },
        "85b493493e4e4562a3db355f57ebe0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7be2d4ab98dc403499c139ab07fd2019",
            "placeholder": "​",
            "style": "IPY_MODEL_6fece36129424ba19164082d28ef51ec",
            "value": "Downloading readme: 100%"
          }
        },
        "5dc5505d11e749b196e8b5cfc42cb588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae55629d068468e834ff1a9ae54d7a2",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9190dbc6d7804b3b9561e3deec3fef11",
            "value": 25
          }
        },
        "de26ae4953f44fe0b6252ae0661aaafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc3b3cbd520148e0983d41196ef891e5",
            "placeholder": "​",
            "style": "IPY_MODEL_7d29a1ae227641e5833e09ebbcaed241",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.28kB/s]"
          }
        },
        "23bf6c6f895b49c689497717cd98a1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be2d4ab98dc403499c139ab07fd2019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fece36129424ba19164082d28ef51ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae55629d068468e834ff1a9ae54d7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9190dbc6d7804b3b9561e3deec3fef11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc3b3cbd520148e0983d41196ef891e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d29a1ae227641e5833e09ebbcaed241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reifircax/automatic-training/blob/main/automatic_model_training_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training your own openWakeWord models\n"
      ],
      "metadata": {
        "id": "vl_FIEj-auGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick-start:** If you just want to train a basic custom model for openWakeWord!\n",
        "\n",
        "Follow the instructions for Step 1 below. Each time you change the wake word, click the play icon to the left of the title to generate a sample and make sure it sounds correct. The first time it takes a few minutes but subsequent runs will be quick.\n",
        "\n",
        "Once you're satisfied with the pronounciation, go to the \"Runtime\" dropdown menu in the upper left of the page, and select \"run all\". Keep the tab open but feel free to do something else. After ~1 hour, your custom model will be ready and will automatically be downloaded to your computer!\n",
        "\n",
        "If you are a Home Assistant user with the openWakeWord add-on, follow the instructions [here](https://github.com/home-assistant/addons/blob/master/openwakeword/DOCS.md#custom-wake-word-models) to install and enable your custom model.\n",
        "\n",
        "---\n",
        "\n",
        "If you are interested in learning more about the custom model training process (and increasing the accuracy of your custom models), read through each step in this notebook and try experimenting with different training parameters. If you have any questions or problems, feel free to start a discussion at the openWakeWord [repo](https://github.com/dscripka/openWakeWord/discussions)."
      ],
      "metadata": {
        "id": "-Q9wEuRdwY_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @markdown # 2. Download Data\n",
        "# @markdown Training custom models requires downloading a wide variety of data\n",
        "# @markdown that will help make the model perform well in real-world scenarios.\n",
        "# @markdown This example notebook will download small samples of background noise,\n",
        "# @markdown music, and Room Impulse Responses (to add echo). This will still produce\n",
        "# @markdown a custom model that performs well, but if you are interested in adding even more,\n",
        "# @markdown feel free to extend this notebook to download the full datasets and even add\n",
        "# @markdown your own!\n",
        "# @markdown\n",
        "# @markdown Downloading this example data will usually take about 15 minutes.\n",
        "\n",
        "# @markdown **Important note!** The data downloaded here has a mixture of different\n",
        "# @markdown licenses and usage restrictions. As such, any custom models trained with this\n",
        "# @markdown data should be considered as appropriate for **non-commercial** personal use only.\n",
        "\n",
        "# ## Install all dependencies\n",
        "# !pip install datasets\n",
        "# !pip install scipy\n",
        "# !pip install tqdm\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "# install openwakeword (full installation to support training)\n",
        "!git clone https://github.com/dscripka/openwakeword\n",
        "!pip install -e ./openwakeword --no-deps\n",
        "# !cd openwakeword\n",
        "\n",
        "# install other dependencies\n",
        "!pip install mutagen==1.47.0\n",
        "!pip install torchinfo==1.8.0\n",
        "!pip install torchmetrics==1.2.0\n",
        "!pip install speechbrain==0.5.14\n",
        "!pip install audiomentations==0.33.0\n",
        "!pip install torch-audiomentations==0.11.0\n",
        "!pip install acoustics==0.2.6\n",
        "# !pip uninstall tensorflow -y\n",
        "# !pip install tensorflow-cpu==2.8.1\n",
        "# !pip install protobuf==3.20.3\n",
        "# !pip install tensorflow_probability==0.16.0\n",
        "# !pip install onnx_tf==1.10.0\n",
        "!pip install onnxruntime==1.22.1 ai_edge_litert==1.4.0 onnxsim\n",
        "!pip install onnx2tf\n",
        "!pip install onnx\n",
        "# !pip install ai_edge_litert==1.2.0\n",
        "!pip install onnx_graphsurgeon\n",
        "!pip install sng4onnx\n",
        "!pip install pronouncing==0.2.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install deep-phonemizer==0.0.19\n",
        "\n",
        "# Download required models (workaround for Colab)\n",
        "import os\n",
        "os.makedirs(\"./openwakeword/openwakeword/resources/models\", exist_ok=True)\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite\n",
        "\n",
        "# Imports\n",
        "import sys\n",
        "\n",
        "if \"piper-sample-generator/\" not in sys.path:\n",
        "    sys.path.append(\"piper-sample-generator/\")\n",
        "from generate_samples import generate_samples\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import yaml\n",
        "import datasets\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Download all data\n",
        "\n",
        "## Download MIR RIR data (takes about ~2 minutes)\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    !git lfs install\n",
        "    !git clone https://huggingface.co/datasets/davidscripka/MIT_environmental_impulse_responses\n",
        "    rir_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"./MIT_environmental_impulse_responses/16khz\").glob(\"*.wav\")]}).cast_column(\"audio\", datasets.Audio())\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    for row in tqdm(rir_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1]\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "## Download noise and background audio (takes about ~3 minutes)\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "    fname = \"bal_train09.tar\"\n",
        "    out_dir = f\"audioset/{fname}\"\n",
        "    link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
        "    !wget -O {out_dir} {link}\n",
        "    !cd audioset && tar -xvf bal_train09.tar\n",
        "\n",
        "    output_dir = \"./audioset_16k\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "    audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "    for row in tqdm(audioset_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset\n",
        "# https://github.com/mdeff/fma\n",
        "\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "    fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    n_hours = 1  # use only 1 hour of clips for this example notebook, recommend increasing for full-scale training\n",
        "    for i in tqdm(range(n_hours*3600//30)):  # this works because the FMA dataset is all 30 second clips\n",
        "        row = next(fma_dataset)\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "        i += 1\n",
        "        if i == n_hours*3600//30:\n",
        "            break\n",
        "\n",
        "# Download pre-computed openWakeWord features for training and validation\n",
        "\n",
        "# training set (~2,000 hours from the ACAV100M Dataset)\n",
        "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
        "if not os.path.exists(\"./openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"):\n",
        "    !wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "\n",
        "# validation set for false positive rate estimation (~11 hours)\n",
        "if not os.path.exists(\"validation_set_features.npy\"):\n",
        "    !wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n"
      ],
      "metadata": {
        "id": "oWahyFO20_mh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c3bc30b2fd244afebb59ec17c2426094",
            "b8eaff451261467cb335d753da33357b",
            "3cc9e9c896154ded80b87ff24971a5e8",
            "52dd96d97087456cba48a87b2c473d8a",
            "418b934cddf540bb989e2ce797fd1df0",
            "1bc538c08b65471a80089150ddb8e2b9",
            "cbfcfeb2a4384a3a846b6162f75e1df7",
            "ded8a90ee44248f68e317fcda0903634",
            "46c1805f82df4228b1e8eddd1d5ef00b",
            "b6f3a8bc9c084e5aa3f5157311c2b188",
            "7a870a47357c4286959818b62e57bcbc",
            "7de734d32b95473cb44e4931875b52d1",
            "85b493493e4e4562a3db355f57ebe0b1",
            "5dc5505d11e749b196e8b5cfc42cb588",
            "de26ae4953f44fe0b6252ae0661aaafc",
            "23bf6c6f895b49c689497717cd98a1d1",
            "7be2d4ab98dc403499c139ab07fd2019",
            "6fece36129424ba19164082d28ef51ec",
            "1ae55629d068468e834ff1a9ae54d7a2",
            "9190dbc6d7804b3b9561e3deec3fef11",
            "dc3b3cbd520148e0983d41196ef891e5",
            "7d29a1ae227641e5833e09ebbcaed241"
          ]
        },
        "outputId": "53658341-e61f-4414-c932-cf7f1215b39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'openwakeword'...\n",
            "remote: Enumerating objects: 1189, done.\u001b[K\n",
            "remote: Counting objects: 100% (607/607), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 1189 (delta 502), reused 477 (delta 477), pack-reused 582 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1189/1189), 3.20 MiB | 23.95 MiB/s, done.\n",
            "Resolving deltas: 100% (735/735), done.\n",
            "Obtaining file:///content/openwakeword\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openwakeword\n",
            "  Building editable for openwakeword (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openwakeword: filename=openwakeword-0.6.0-0.editable-py3-none-any.whl size=17450 sha256=1e63c168bd0ed597ebf1708d64cf1e07727f9c0c1a2588a21ea203a840b68ad2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_ru6pe26/wheels/95/b4/6f/f887431fea7b3379ef42ac3594a92164114b83a95abb8b7969\n",
            "Successfully built openwakeword\n",
            "Installing collected packages: openwakeword\n",
            "Successfully installed openwakeword-0.6.0\n",
            "Collecting mutagen==1.47.0\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mutagen\n",
            "Successfully installed mutagen-1.47.0\n",
            "Collecting torchinfo==1.8.0\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torchmetrics==1.2.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.2.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.2.0) (2.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.2.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.2)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.2.0\n",
            "Collecting speechbrain==0.5.14\n",
            "  Downloading speechbrain-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hyperpyyaml (from speechbrain==0.5.14)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (25.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (0.2.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (2.5.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from speechbrain==0.5.14) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->speechbrain==0.5.14) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->speechbrain==0.5.14) (1.1.8)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2025.8.3)\n",
            "Downloading speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.0/519.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12 speechbrain-0.5.14\n",
            "Collecting audiomentations==0.33.0\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from audiomentations==0.33.0) (2.0.2)\n",
            "Collecting librosa!=0.10.0,<0.11.0,>=0.8.0 (from audiomentations==0.33.0)\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from audiomentations==0.33.0) (1.16.1)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.15.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.22)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2025.8.3)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: librosa, audiomentations\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "Successfully installed audiomentations-0.33.0 librosa-0.10.2.post1\n",
            "Collecting torch-audiomentations==0.11.0\n",
            "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations==0.11.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations==0.11.0) (2.5.0)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations==0.11.0) (2.5.0)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations==0.11.0)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.15.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2025.8.3)\n",
            "Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Building wheels for collected packages: julius\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=903c5e65b92847e0fbf53f72df9185608ba38b28a8743e3f4316748e813d4b0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
            "Successfully built julius\n",
            "Installing collected packages: primePy, julius, torch-pitch-shift, torch-audiomentations\n",
            "Successfully installed julius-0.2.7 primePy-1.3 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.5\n",
            "Collecting acoustics==0.2.6\n",
            "  Downloading acoustics-0.2.6.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (1.16.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (3.10.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (1.17.0)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from acoustics==0.2.6) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->acoustics==0.2.6) (3.2.3)\n",
            "Building wheels for collected packages: acoustics\n",
            "  Building wheel for acoustics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.6-py3-none-any.whl size=68221 sha256=f17cfad111260d5ffe553c8a83f98a47034bb9c1bf020c8ef3fd2a38b410d9cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/b9/23/97e90b860366fe151516b329c5306a719e1e6c46030f878320\n",
            "Successfully built acoustics\n",
            "Installing collected packages: acoustics\n",
            "Successfully installed acoustics-0.2.6\n",
            "Requirement already satisfied: onnxruntime==1.22.1 in /usr/local/lib/python3.12/dist-packages (1.22.1)\n",
            "Collecting ai_edge_litert==1.4.0\n",
            "  Downloading ai_edge_litert-1.4.0-cp312-cp312-manylinux_2_17_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36.tar.gz (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime==1.22.1) (1.13.1)\n",
            "Collecting backports.strenum (from ai_edge_litert==1.4.0)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai_edge_litert==1.4.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ai_edge_litert==1.4.0) (4.15.0)\n",
            "Collecting onnx (from onnxsim)\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime==1.22.1) (10.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx->onnxsim) (0.5.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime==1.22.1) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading ai_edge_litert-1.4.0-cp312-cp312-manylinux_2_17_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: onnxsim\n",
            "  Building wheel for onnxsim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnxsim: filename=onnxsim-0.4.36-cp312-cp312-linux_x86_64.whl size=2200367 sha256=3160709a17664724d18d140327890da954e1bcdc55ed2fced095cf3669382d69\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/5d/cc/db1350d9fabfe7f8442b5d97aff2ff543fc253277f71a6508f\n",
            "Successfully built onnxsim\n",
            "Installing collected packages: backports.strenum, onnx, ai_edge_litert, onnxsim\n",
            "Successfully installed ai_edge_litert-1.4.0 backports.strenum-1.2.8 onnx-1.19.0 onnxsim-0.4.36\n",
            "Collecting onnx2tf\n",
            "  Downloading onnx2tf-1.28.2-py3-none-any.whl.metadata (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx2tf-1.28.2-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.3/468.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx2tf\n",
            "Successfully installed onnx2tf-1.28.2\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Collecting onnx_graphsurgeon\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnx_graphsurgeon) (2.0.2)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from onnx_graphsurgeon) (1.19.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.14.0->onnx_graphsurgeon) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.14.0->onnx_graphsurgeon) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx>=1.14.0->onnx_graphsurgeon) (0.5.3)\n",
            "Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_graphsurgeon\n",
            "Successfully installed onnx_graphsurgeon-0.5.8\n",
            "Collecting sng4onnx\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: sng4onnx\n",
            "Successfully installed sng4onnx-1.0.4\n",
            "Collecting pronouncing==0.2.0\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing==0.2.0)\n",
            "  Downloading cmudict-1.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.12/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.23.0)\n",
            "Downloading cmudict-1.1.1-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6234 sha256=8d54f40a38a2ca389a04dfda1d1bb69eb9f5e7bf77424a4242c536b09157f711\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/76/15/dfdf38731993cdc4e86fd6d949c70c0e9786cf00073d8114d4\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.1.1 pronouncing-0.2.0\n",
            "Collecting datasets==2.14.6\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (18.1.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (0.70.16)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.6) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.8.3)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.6 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dill"
                ]
              },
              "id": "39996725a2ec4775a5c3ca29a6ddb5fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-phonemizer==0.0.19\n",
            "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (6.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (2.19.0)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (2025.8.3)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (0.45.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.12/dist-packages (from deep-phonemizer==0.0.19) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer==0.0.19) (3.0.2)\n",
            "Building wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33272 sha256=5f85997d8400c3699e500814b2119682f89c51d434017e7ee44648d1cdd77983\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/d7/45/f2ae07184a29327b2a7f93b1f734a936c3a34e57225fca603b\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.19\n",
            "--2025-09-03 23:48:13--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A47%3A01Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A46%3A27Z&ske=2025-09-04T00%3A47%3A01Z&sks=b&skv=2018-11-09&sig=xP6ad3XInFBj%2Bo33UtgSJdgtVEYpfBFeS2%2F%2FF%2B8Ol90%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-03 23:48:13--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A47%3A01Z&rscd=attachment%3B+filename%3Dembedding_model.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A46%3A27Z&ske=2025-09-04T00%3A47%3A01Z&sks=b&skv=2018-11-09&sig=xP6ad3XInFBj%2Bo33UtgSJdgtVEYpfBFeS2%2F%2FF%2B8Ol90%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1326578 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-03 23:48:13 (43.0 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
            "\n",
            "--2025-09-03 23:48:13--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A46%3A59Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A46%3A39Z&ske=2025-09-04T00%3A46%3A59Z&sks=b&skv=2018-11-09&sig=aq%2BBx1pzdTBGZ8P81Hsmr5ORj%2BV0dv0VUzaUKcitbIM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-03 23:48:13--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A46%3A59Z&rscd=attachment%3B+filename%3Dembedding_model.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A46%3A39Z&ske=2025-09-04T00%3A46%3A59Z&sks=b&skv=2018-11-09&sig=aq%2BBx1pzdTBGZ8P81Hsmr5ORj%2BV0dv0VUzaUKcitbIM%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330312 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-03 23:48:13 (26.3 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
            "\n",
            "--2025-09-03 23:48:13--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A46%3A03Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A45%3A53Z&ske=2025-09-04T00%3A46%3A03Z&sks=b&skv=2018-11-09&sig=dZilCCsIqA6Xw%2FB56%2Fs4V0sA2MLCveU5t%2BSNpCYaryo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-03 23:48:14--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/6b613c12-b693-4220-82d5-01be396893d9?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A46%3A03Z&rscd=attachment%3B+filename%3Dmelspectrogram.onnx&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A45%3A53Z&ske=2025-09-04T00%3A46%3A03Z&sks=b&skv=2018-11-09&sig=dZilCCsIqA6Xw%2FB56%2Fs4V0sA2MLCveU5t%2BSNpCYaryo%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5MywibmJmIjoxNzU2OTQzMjkzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.u7GCLl6JfUXOPiaY93zgkK4BOQq7buLEbg5K3vd_Yz0&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1087958 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-03 23:48:14 (32.1 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
            "\n",
            "--2025-09-03 23:48:14--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A45%3A32Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A44%3A49Z&ske=2025-09-04T00%3A45%3A32Z&sks=b&skv=2018-11-09&sig=GDnfQtApXv7RHqRwKk81xSEchCIWEVAGR1ScWtnfv20%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5NCwibmJmIjoxNzU2OTQzMjk0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.wOddgloMHfptOXhaevJVvWeF0KgPDnD8lizE-MuDS_M&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-03 23:48:14--  https://release-assets.githubusercontent.com/github-production-release-asset/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-04T00%3A45%3A32Z&rscd=attachment%3B+filename%3Dmelspectrogram.tflite&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-03T23%3A44%3A49Z&ske=2025-09-04T00%3A45%3A32Z&sks=b&skv=2018-11-09&sig=GDnfQtApXv7RHqRwKk81xSEchCIWEVAGR1ScWtnfv20%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Njk0MzU5NCwibmJmIjoxNzU2OTQzMjk0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.wOddgloMHfptOXhaevJVvWeF0KgPDnD8lizE-MuDS_M&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092516 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-03 23:48:14 (35.5 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
            "\n",
            "Git LFS initialized.\n",
            "Cloning into 'MIT_environmental_impulse_responses'...\n",
            "remote: Enumerating objects: 280, done.\u001b[K\n",
            "remote: Total 280 (delta 0), reused 0 (delta 0), pack-reused 280 (from 1)\u001b[K\n",
            "Receiving objects: 100% (280/280), 41.11 KiB | 8.22 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Filtering content: 100% (270/270), 7.99 MiB | 6.19 MiB/s, done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [00:19<00:00, 13.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-03 23:48:38--  https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/bal_train09.tar\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64897793837ad032c6c25d5b/2da2b65f06f00bed3429be9aa923ef69e211152b1fb32ba30d24630ef3095c32?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T234838Z&X-Amz-Expires=3600&X-Amz-Signature=20f10002e76b28ca0d247e8eed582553f3d53defb46429c1fdc9c81daf9796c1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bal_train09.tar%3B+filename%3D%22bal_train09.tar%22%3B&response-content-type=application%2Fx-tar&x-id=GetObject&Expires=1756946918&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NjkxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDg5Nzc5MzgzN2FkMDMyYzZjMjVkNWIvMmRhMmI2NWYwNmYwMGJlZDM0MjliZTlhYTkyM2VmNjllMjExMTUyYjFmYjMyYmEzMGQyNDYzMGVmMzA5NWMzMioifV19&Signature=nmbU-6WQvFjt0mwcCyWvvsMef4K9pUMf5SKtyigr%7EQ8mScXoWcBvle4Mexv53l%7EhAnYoIuP%7EAXpYGmEqZv87MNre-or6jCAZ0PHgW593Hj1Q8RcGevLve2np%7EpETVBYY2Xntn4v58N5wErLYWh1PP%7Eh2H%7EFQCC%7Ek-frh-TogM77xjRbTGq1BHGl4ix9o0l1wuISzmvCZkjUqLz-ZVXb6mgljNbjgM8KqcIUBlzwtWzS9TEvs4DzEhkO2sJG3pHDATzY1IH-3km1Ae44rR1AynqFvj60fiF0HZLlNoN27bKvuPhapI9zia6Vxlzkba3Or%7Ec0a1dRrbl7vi3vB-UtnjQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-03 23:48:38--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64897793837ad032c6c25d5b/2da2b65f06f00bed3429be9aa923ef69e211152b1fb32ba30d24630ef3095c32?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T234838Z&X-Amz-Expires=3600&X-Amz-Signature=20f10002e76b28ca0d247e8eed582553f3d53defb46429c1fdc9c81daf9796c1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bal_train09.tar%3B+filename%3D%22bal_train09.tar%22%3B&response-content-type=application%2Fx-tar&x-id=GetObject&Expires=1756946918&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NjkxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDg5Nzc5MzgzN2FkMDMyYzZjMjVkNWIvMmRhMmI2NWYwNmYwMGJlZDM0MjliZTlhYTkyM2VmNjllMjExMTUyYjFmYjMyYmEzMGQyNDYzMGVmMzA5NWMzMioifV19&Signature=nmbU-6WQvFjt0mwcCyWvvsMef4K9pUMf5SKtyigr%7EQ8mScXoWcBvle4Mexv53l%7EhAnYoIuP%7EAXpYGmEqZv87MNre-or6jCAZ0PHgW593Hj1Q8RcGevLve2np%7EpETVBYY2Xntn4v58N5wErLYWh1PP%7Eh2H%7EFQCC%7Ek-frh-TogM77xjRbTGq1BHGl4ix9o0l1wuISzmvCZkjUqLz-ZVXb6mgljNbjgM8KqcIUBlzwtWzS9TEvs4DzEhkO2sJG3pHDATzY1IH-3km1Ae44rR1AynqFvj60fiF0HZLlNoN27bKvuPhapI9zia6Vxlzkba3Or%7Ec0a1dRrbl7vi3vB-UtnjQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.239.83.16, 18.239.83.59, 18.239.83.61, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.239.83.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 968540160 (924M) [application/x-tar]\n",
            "Saving to: ‘audioset/bal_train09.tar’\n",
            "\n",
            "audioset/bal_train0 100%[===================>] 923.67M   113MB/s    in 8.7s    \n",
            "\n",
            "2025-09-03 23:48:47 (106 MB/s) - ‘audioset/bal_train09.tar’ saved [968540160/968540160]\n",
            "\n",
            "audio/bal_train/lsrlvha5Z_M.flac\n",
            "audio/bal_train/lu3jRbYs780.flac\n",
            "audio/bal_train/lt-jiIXkOmY.flac\n",
            "audio/bal_train/luVp3elLSGQ.flac\n",
            "audio/bal_train/lvi0RjGP2R8.flac\n",
            "audio/bal_train/lvV-7jYDNZs.flac\n",
            "audio/bal_train/luWrlEnvmoQ.flac\n",
            "audio/bal_train/luxVmtNzH1U.flac\n",
            "audio/bal_train/lvtAPn1aqQc.flac\n",
            "audio/bal_train/lv6op2HHIuM.flac\n",
            "audio/bal_train/lwCZZEBgqg8.flac\n",
            "audio/bal_train/lw-PPnW91Io.flac\n",
            "audio/bal_train/lwLk_X9xYJA.flac\n",
            "audio/bal_train/lwQVcLxFBIQ.flac\n",
            "audio/bal_train/lxDDJu4Sgco.flac\n",
            "audio/bal_train/lxDKoov1RoU.flac\n",
            "audio/bal_train/m--xEFqqrLc.flac\n",
            "audio/bal_train/lxrDreCz5BE.flac\n",
            "audio/bal_train/lyapYAgakgs.flac\n",
            "audio/bal_train/lxzSLdwUQyM.flac\n",
            "audio/bal_train/lz8Y28KnnFM.flac\n",
            "audio/bal_train/lyuULnLsc4w.flac\n",
            "audio/bal_train/m-Hl77LCkWw.flac\n",
            "audio/bal_train/m-GGo6D1qnw.flac\n",
            "audio/bal_train/m-VO1GSLsfE.flac\n",
            "audio/bal_train/m-Qo35y4GPQ.flac\n",
            "audio/bal_train/m-S-yqzlOj4.flac\n",
            "audio/bal_train/m-eyGzf9Ux4.flac\n",
            "audio/bal_train/m0FhT3UnXjA.flac\n",
            "audio/bal_train/m0_NYTFhvgs.flac\n",
            "audio/bal_train/m0vwa8RWzXg.flac\n",
            "audio/bal_train/m1yOTcjRjcM.flac\n",
            "audio/bal_train/m29qZYx1sHc.flac\n",
            "audio/bal_train/m1ov6te6jK8.flac\n",
            "audio/bal_train/m160FX9Sln8.flac\n",
            "audio/bal_train/m1k9Selk_3I.flac\n",
            "audio/bal_train/m2QZEuu2n18.flac\n",
            "audio/bal_train/m2MOS4hpwxo.flac\n",
            "audio/bal_train/m2SM-SdOJxI.flac\n",
            "audio/bal_train/m2g9-zbgdIM.flac\n",
            "audio/bal_train/m2d1CFe1Ono.flac\n",
            "audio/bal_train/m2h996KM-iY.flac\n",
            "audio/bal_train/m2qOCSn0nKM.flac\n",
            "audio/bal_train/m3DJiOxB-ns.flac\n",
            "audio/bal_train/m2zs1UGyrcc.flac\n",
            "audio/bal_train/m3M8wMyXmUk.flac\n",
            "audio/bal_train/m3ea7VjRNR4.flac\n",
            "audio/bal_train/m3QtD1HEHOg.flac\n",
            "audio/bal_train/m3gTh1f-8pk.flac\n",
            "audio/bal_train/m4Mo4aXY0w4.flac\n",
            "audio/bal_train/m3kb8GFAvtI.flac\n",
            "audio/bal_train/m4bBsvuS4EU.flac\n",
            "audio/bal_train/m52UhgCxmaE.flac\n",
            "audio/bal_train/m50hi3spgZ4.flac\n",
            "audio/bal_train/m5F0Lq03spM.flac\n",
            "audio/bal_train/m5IvF38dyD8.flac\n",
            "audio/bal_train/m5QM9f_r4qY.flac\n",
            "audio/bal_train/m6PtVTwG4UI.flac\n",
            "audio/bal_train/m5UX38J1UoU.flac\n",
            "audio/bal_train/m6Q53Ouf0AM.flac\n",
            "audio/bal_train/m6d2TTB8VM0.flac\n",
            "audio/bal_train/m7HwQGX_zjA.flac\n",
            "audio/bal_train/m8-aK8egg84.flac\n",
            "audio/bal_train/m87mO5m2LmU.flac\n",
            "audio/bal_train/m8ZA49ubaf8.flac\n",
            "audio/bal_train/m8bBtOHRVTA.flac\n",
            "audio/bal_train/m8cWrsyJQto.flac\n",
            "audio/bal_train/m8poFnEbvW8.flac\n",
            "audio/bal_train/m8qlGtuazZM.flac\n",
            "audio/bal_train/m8uHowdxvsE.flac\n",
            "audio/bal_train/mA1UxREUs5c.flac\n",
            "audio/bal_train/m9l9Qr0odVA.flac\n",
            "audio/bal_train/m9tnNkon_iw.flac\n",
            "audio/bal_train/mB2FAS0DNkk.flac\n",
            "audio/bal_train/m8wx0nDP6C4.flac\n",
            "audio/bal_train/mAmaUI7_uZ0.flac\n",
            "audio/bal_train/mBGGuMrp9ko.flac\n",
            "audio/bal_train/mBG-st0VUXs.flac\n",
            "audio/bal_train/mBNvhnsEOrc.flac\n",
            "audio/bal_train/mBWqKWuqiTE.flac\n",
            "audio/bal_train/mCKwki7LeZ4.flac\n",
            "audio/bal_train/mCX6SHv3OUQ.flac\n",
            "audio/bal_train/mD-Ec0NsjIg.flac\n",
            "audio/bal_train/mDYp4Ks6JXc.flac\n",
            "audio/bal_train/mDR4fr0TnaM.flac\n",
            "audio/bal_train/mDx0YO-kz3g.flac\n",
            "audio/bal_train/mEHNGl0WQU8.flac\n",
            "audio/bal_train/mEUh6uoj7qc.flac\n",
            "audio/bal_train/mEDLOYAiXCE.flac\n",
            "audio/bal_train/mFcHGbnNtSQ.flac\n",
            "audio/bal_train/mFp1nrnlGx4.flac\n",
            "audio/bal_train/mFyS3HekU9o.flac\n",
            "audio/bal_train/mFwURBjeSn8.flac\n",
            "audio/bal_train/mG7ZlbuEcr4.flac\n",
            "audio/bal_train/mG4m7Kga5Rs.flac\n",
            "audio/bal_train/mGU4ZRstxpY.flac\n",
            "audio/bal_train/mH2y5B7aTWo.flac\n",
            "audio/bal_train/mGD6gamyX5A.flac\n",
            "audio/bal_train/mHWFt9zlMYU.flac\n",
            "audio/bal_train/mHduLcb-gXc.flac\n",
            "audio/bal_train/mHPeZzWcOeQ.flac\n",
            "audio/bal_train/mHxGqJ4A_XA.flac\n",
            "audio/bal_train/mHf7COLGcD0.flac\n",
            "audio/bal_train/mHsq8CQryyU.flac\n",
            "audio/bal_train/mIneYo1xzM0.flac\n",
            "audio/bal_train/mIkW7mWlnXw.flac\n",
            "audio/bal_train/mJX_kwUUQ5A.flac\n",
            "audio/bal_train/mKIapkfnAGY.flac\n",
            "audio/bal_train/mJEmgYJ7Z4s.flac\n",
            "audio/bal_train/mK3O4H_PNUk.flac\n",
            "audio/bal_train/mJKaCvaWPu8.flac\n",
            "audio/bal_train/mKygFOtbUDI.flac\n",
            "audio/bal_train/mKtM5YPwgQk.flac\n",
            "audio/bal_train/mLgKcmNnMyw.flac\n",
            "audio/bal_train/mLGcsQKHLLg.flac\n",
            "audio/bal_train/mLK8eG2JcB8.flac\n",
            "audio/bal_train/mLsXR-EqyVo.flac\n",
            "audio/bal_train/mL3GCt-X9Nk.flac\n",
            "audio/bal_train/mLR9bx1mS90.flac\n",
            "audio/bal_train/mMT1kEejAG8.flac\n",
            "audio/bal_train/mMJPbv1LijI.flac\n",
            "audio/bal_train/mNVGTRu7120.flac\n",
            "audio/bal_train/mOFyRCMlXIo.flac\n",
            "audio/bal_train/mOmHE_P9znc.flac\n",
            "audio/bal_train/mNsYlojC_kM.flac\n",
            "audio/bal_train/mOCrTCUuPR8.flac\n",
            "audio/bal_train/mO99Qlj7csQ.flac\n",
            "audio/bal_train/mPqj688FJLY.flac\n",
            "audio/bal_train/mOYkqGGq82Q.flac\n",
            "audio/bal_train/mOmYcOBqhwo.flac\n",
            "audio/bal_train/mOnPgI8vfiQ.flac\n",
            "audio/bal_train/mOzJBSUH28g.flac\n",
            "audio/bal_train/mQ1E8rx2dnI.flac\n",
            "audio/bal_train/mOx0YEidsIg.flac\n",
            "audio/bal_train/mR10DRflzF0.flac\n",
            "audio/bal_train/mRKud6yP4iU.flac\n",
            "audio/bal_train/mQNUrYoFM2E.flac\n",
            "audio/bal_train/mQBb5YLdaEU.flac\n",
            "audio/bal_train/mRSAoBtjLjI.flac\n",
            "audio/bal_train/mRhxMKJsTjg.flac\n",
            "audio/bal_train/mRigmHeo4dE.flac\n",
            "audio/bal_train/mSidbz4LB_A.flac\n",
            "audio/bal_train/mRgeey05UNs.flac\n",
            "audio/bal_train/mT4ApkTyEAw.flac\n",
            "audio/bal_train/mSM-W0CorRY.flac\n",
            "audio/bal_train/mTUgsPfWiwM.flac\n",
            "audio/bal_train/mS9Ycwq6p7Y.flac\n",
            "audio/bal_train/mTXBC3peZU0.flac\n",
            "audio/bal_train/mT5tvjwIPOo.flac\n",
            "audio/bal_train/mTzn4_0qVwc.flac\n",
            "audio/bal_train/mTeBbj9nIMU.flac\n",
            "audio/bal_train/mU6cfEWw5Og.flac\n",
            "audio/bal_train/mTgLozfklVc.flac\n",
            "audio/bal_train/mU-Z9qP6SWc.flac\n",
            "audio/bal_train/mV3SLqlHCI0.flac\n",
            "audio/bal_train/mUqHiEeLGPk.flac\n",
            "audio/bal_train/mVPswGyxPNY.flac\n",
            "audio/bal_train/mX45CiTjf8I.flac\n",
            "audio/bal_train/mUE-IlUrLr8.flac\n",
            "audio/bal_train/mVamaP3xUw0.flac\n",
            "audio/bal_train/mWL9_WIbykw.flac\n",
            "audio/bal_train/mVDMBQ1ex3A.flac\n",
            "audio/bal_train/mWS_2Cq85VQ.flac\n",
            "audio/bal_train/mWuX--EEq2E.flac\n",
            "audio/bal_train/mXez6CVBpuo.flac\n",
            "audio/bal_train/mXpUZpMLANw.flac\n",
            "audio/bal_train/mVpOTaBG98o.flac\n",
            "audio/bal_train/mY734i-keE0.flac\n",
            "audio/bal_train/mYHnQPDiatw.flac\n",
            "audio/bal_train/mYjaMHySsr4.flac\n",
            "audio/bal_train/mYRRnFNNIBo.flac\n",
            "audio/bal_train/mYpQQGbQfdo.flac\n",
            "audio/bal_train/mYsjO2kEXRA.flac\n",
            "audio/bal_train/m_39THY6PfY.flac\n",
            "audio/bal_train/mYuaLETWuHo.flac\n",
            "audio/bal_train/mYwlJS_9fTA.flac\n",
            "audio/bal_train/m_YrYZlGvKQ.flac\n",
            "audio/bal_train/mYsyMyNO7Ss.flac\n",
            "audio/bal_train/mZNNWTrvGoA.flac\n",
            "audio/bal_train/mZkuT_G8z5M.flac\n",
            "audio/bal_train/maBGQMZwkzE.flac\n",
            "audio/bal_train/m_R8mUEGEYk.flac\n",
            "audio/bal_train/maZ3b5w6xVI.flac\n",
            "audio/bal_train/macnXLRXbHU.flac\n",
            "audio/bal_train/madJjLKi7HA.flac\n",
            "audio/bal_train/maeD_--0hXs.flac\n",
            "audio/bal_train/mb9wdN5X1Lc.flac\n",
            "audio/bal_train/mcA_nVdrI0A.flac\n",
            "audio/bal_train/maeSHVZX8xc.flac\n",
            "audio/bal_train/mcAsO331Z9s.flac\n",
            "audio/bal_train/mcW6dEO9jx0.flac\n",
            "audio/bal_train/mbeFh6O1sz4.flac\n",
            "audio/bal_train/mcQppzCub6Q.flac\n",
            "audio/bal_train/mcyM8m5D8uE.flac\n",
            "audio/bal_train/mcnhvoxV0MM.flac\n",
            "audio/bal_train/md2197NFr6U.flac\n",
            "audio/bal_train/mdF8mqA6864.flac\n",
            "audio/bal_train/mdOZIOc8SA4.flac\n",
            "audio/bal_train/mdl1FaVWz5c.flac\n",
            "audio/bal_train/meDp9QWKHvo.flac\n",
            "audio/bal_train/mdxVlQ69E0s.flac\n",
            "audio/bal_train/me8s0oanAgI.flac\n",
            "audio/bal_train/meRSUP8yDlE.flac\n",
            "audio/bal_train/metVVdfT_0w.flac\n",
            "audio/bal_train/mf7DRiLh9O8.flac\n",
            "audio/bal_train/me_X5bkJBiA.flac\n",
            "audio/bal_train/mf7lZOWnUfs.flac\n",
            "audio/bal_train/mfAwXBjYQkk.flac\n",
            "audio/bal_train/mgF-2P1XPwk.flac\n",
            "audio/bal_train/mggMsSBOgJ4.flac\n",
            "audio/bal_train/mgVU7begFtE.flac\n",
            "audio/bal_train/mglgIu_n6Bw.flac\n",
            "audio/bal_train/mglgm-Pa1uk.flac\n",
            "audio/bal_train/mgnurQzxmbg.flac\n",
            "audio/bal_train/mh1qPW97AvQ.flac\n",
            "audio/bal_train/mh3KaP-1oQM.flac\n",
            "audio/bal_train/mhD7n0YxWMk.flac\n",
            "audio/bal_train/mhZXWq239lI.flac\n",
            "audio/bal_train/mhAehJFIDk4.flac\n",
            "audio/bal_train/mhPP6pnisL4.flac\n",
            "audio/bal_train/mher704il6I.flac\n",
            "audio/bal_train/mhFeUbaq9uc.flac\n",
            "audio/bal_train/mhru3GXbkHY.flac\n",
            "audio/bal_train/mhdhVMlSbv8.flac\n",
            "audio/bal_train/mhmbzf2Bb7s.flac\n",
            "audio/bal_train/mhuCtff8KzI.flac\n",
            "audio/bal_train/mhwXJqvRaDw.flac\n",
            "audio/bal_train/mjYpSGVocWM.flac\n",
            "audio/bal_train/milHiN94luM.flac\n",
            "audio/bal_train/miqwRA1QLw8.flac\n",
            "audio/bal_train/mjCjss_Ot9g.flac\n",
            "audio/bal_train/miwuZGdJKtI.flac\n",
            "audio/bal_train/mixOlOTYoq8.flac\n",
            "audio/bal_train/mjZylz3nCwQ.flac\n",
            "audio/bal_train/mi-s3pLeR3U.flac\n",
            "audio/bal_train/mjeUSD_pC9I.flac\n",
            "audio/bal_train/mjhonmjOPRA.flac\n",
            "audio/bal_train/mk3b2BgeyhA.flac\n",
            "audio/bal_train/mkCSJLUMjkM.flac\n",
            "audio/bal_train/mkHWvl9nhBo.flac\n",
            "audio/bal_train/mkM-NrxqNXA.flac\n",
            "audio/bal_train/mkQ2pXkYjRM.flac\n",
            "audio/bal_train/mkfXplU5Ta4.flac\n",
            "audio/bal_train/mkcMF8slW94.flac\n",
            "audio/bal_train/mkl6aKt1vII.flac\n",
            "audio/bal_train/mlJ28r8YxOg.flac\n",
            "audio/bal_train/mlPtGad-EWw.flac\n",
            "audio/bal_train/mlpTCec4igo.flac\n",
            "audio/bal_train/mlKprdc4W94.flac\n",
            "audio/bal_train/mlrarQ5nVlU.flac\n",
            "audio/bal_train/mm0bW4giN0g.flac\n",
            "audio/bal_train/mm3rBzXQI-k.flac\n",
            "audio/bal_train/mmAigxjQbtE.flac\n",
            "audio/bal_train/mmL5v36jxhQ.flac\n",
            "audio/bal_train/mmUnFhFelUI.flac\n",
            "audio/bal_train/mnerUsvZF-M.flac\n",
            "audio/bal_train/mmWIB3zPx9U.flac\n",
            "audio/bal_train/mmRtJhecp14.flac\n",
            "audio/bal_train/mmz6uoEWxuE.flac\n",
            "audio/bal_train/mnsjeTIqbYw.flac\n",
            "audio/bal_train/mpikDeSk-mM.flac\n",
            "audio/bal_train/mnh9RHyGB9A.flac\n",
            "audio/bal_train/mpymEs4Mcw8.flac\n",
            "audio/bal_train/mraRXjjIAUc.flac\n",
            "audio/bal_train/mpysslA_qXc.flac\n",
            "audio/bal_train/mrizjiY5PvI.flac\n",
            "audio/bal_train/mqutrIKQ0wM.flac\n",
            "audio/bal_train/msZvt9_kbuU.flac\n",
            "audio/bal_train/mrwREyYUFMc.flac\n",
            "audio/bal_train/mt0yYRDpd74.flac\n",
            "audio/bal_train/msnm_tYXcYw.flac\n",
            "audio/bal_train/mtLO4RcFIG0.flac\n",
            "audio/bal_train/mtjUgt-IUV8.flac\n",
            "audio/bal_train/mtapmFDmImA.flac\n",
            "audio/bal_train/mtkzMU5w3ms.flac\n",
            "audio/bal_train/mu5K4FA2rVw.flac\n",
            "audio/bal_train/mtuiEDBKgBU.flac\n",
            "audio/bal_train/mtlPekeC9n8.flac\n",
            "audio/bal_train/mu0dlj8ibA4.flac\n",
            "audio/bal_train/mu15Ib_0mgs.flac\n",
            "audio/bal_train/muNZxQqWnt0.flac\n",
            "audio/bal_train/musurEy0zWI.flac\n",
            "audio/bal_train/muTEkKFEoGY.flac\n",
            "audio/bal_train/mv1-e-GmoNQ.flac\n",
            "audio/bal_train/mwG7z_aowKw.flac\n",
            "audio/bal_train/mvR4q_p6Bz4.flac\n",
            "audio/bal_train/mw6Ffj6Pzss.flac\n",
            "audio/bal_train/mwA_Z3AgWxw.flac\n",
            "audio/bal_train/mvuyZMh6vD8.flac\n",
            "audio/bal_train/mwLrABPxvgA.flac\n",
            "audio/bal_train/mwV1X8bpi2g.flac\n",
            "audio/bal_train/mwe2416JIO8.flac\n",
            "audio/bal_train/mwafAXvcoso.flac\n",
            "audio/bal_train/mwqluX7sXXU.flac\n",
            "audio/bal_train/mwwnfWgV_5U.flac\n",
            "audio/bal_train/mx7kjFY7ALs.flac\n",
            "audio/bal_train/mxx2CYAGGkg.flac\n",
            "audio/bal_train/my3ozhGOpsg.flac\n",
            "audio/bal_train/myGffB4WcF8.flac\n",
            "audio/bal_train/my65DVXCPu4.flac\n",
            "audio/bal_train/myGef3nriL8.flac\n",
            "audio/bal_train/myWiV_HMXtc.flac\n",
            "audio/bal_train/mys9igOwNMI.flac\n",
            "audio/bal_train/mza0DdYCGM4.flac\n",
            "audio/bal_train/mz0yo2lOYjo.flac\n",
            "audio/bal_train/n-4rwju_TuM.flac\n",
            "audio/bal_train/mziZiYYd8hI.flac\n",
            "audio/bal_train/n00NFbjv3WU.flac\n",
            "audio/bal_train/n-ndePnWdjg.flac\n",
            "audio/bal_train/n-qlHKbwTzQ.flac\n",
            "audio/bal_train/n0AtY_cAz04.flac\n",
            "audio/bal_train/n08qMfFB_UM.flac\n",
            "audio/bal_train/n0Jc1i6Ns4g.flac\n",
            "audio/bal_train/n0P4klG9TFE.flac\n",
            "audio/bal_train/n0fEWekE2P0.flac\n",
            "audio/bal_train/n0l3y811vWk.flac\n",
            "audio/bal_train/n1PTn_NH_K0.flac\n",
            "audio/bal_train/n16ZUTfZtDM.flac\n",
            "audio/bal_train/n179cK8EubU.flac\n",
            "audio/bal_train/n1zRnTCaiE0.flac\n",
            "audio/bal_train/n2g-33m8YRw.flac\n",
            "audio/bal_train/n34UcYLSKxQ.flac\n",
            "audio/bal_train/n3EeS2mVU5w.flac\n",
            "audio/bal_train/n3QsFeGadEE.flac\n",
            "audio/bal_train/n2SLCHAvUVk.flac\n",
            "audio/bal_train/n3LBDC2ti44.flac\n",
            "audio/bal_train/n49a9hw0iag.flac\n",
            "audio/bal_train/n4QSYx4wVQg.flac\n",
            "audio/bal_train/n4SB8G0dAYw.flac\n",
            "audio/bal_train/n4o1r8Ai66o.flac\n",
            "audio/bal_train/n5CNDVuGtK0.flac\n",
            "audio/bal_train/n5g96qczt5E.flac\n",
            "audio/bal_train/n5BA9O6I0Wo.flac\n",
            "audio/bal_train/n6QjjfstlUI.flac\n",
            "audio/bal_train/n6qb1iEF-Oc.flac\n",
            "audio/bal_train/n87PCgYm6mE.flac\n",
            "audio/bal_train/n8_v_iLmrcE.flac\n",
            "audio/bal_train/n9FC6LnHT7A.flac\n",
            "audio/bal_train/n9bU3ZPCOp0.flac\n",
            "audio/bal_train/n9hp1D7WulI.flac\n",
            "audio/bal_train/nA-Xkv5pIEo.flac\n",
            "audio/bal_train/nB2Lf5TTmBs.flac\n",
            "audio/bal_train/nBEz-wfq8Ew.flac\n",
            "audio/bal_train/nBEhMySwyTw.flac\n",
            "audio/bal_train/nBiHncFD0dM.flac\n",
            "audio/bal_train/nCHBQxWQWlk.flac\n",
            "audio/bal_train/nCPTRcZb4Bk.flac\n",
            "audio/bal_train/nCREOM7DmY8.flac\n",
            "audio/bal_train/nD1rj9eSSm4.flac\n",
            "audio/bal_train/nDMH6C6XLlw.flac\n",
            "audio/bal_train/nDTXpjXKeGs.flac\n",
            "audio/bal_train/nDfjIxcNlKw.flac\n",
            "audio/bal_train/nD_HctFk3Hc.flac\n",
            "audio/bal_train/nE77lQzPBpA.flac\n",
            "audio/bal_train/nDjfeUwA380.flac\n",
            "audio/bal_train/nEgaxoH97kI.flac\n",
            "audio/bal_train/nErs1N5a7dY.flac\n",
            "audio/bal_train/nEuJJd7nLrY.flac\n",
            "audio/bal_train/nFMJ84wyVi0.flac\n",
            "audio/bal_train/nFA1TD9ySXU.flac\n",
            "audio/bal_train/nFCrFcPdu7o.flac\n",
            "audio/bal_train/nF2qiya1Ul4.flac\n",
            "audio/bal_train/nFMtlnKFVKQ.flac\n",
            "audio/bal_train/nFkXTMHcjMU.flac\n",
            "audio/bal_train/nFdmth2N8Bo.flac\n",
            "audio/bal_train/nG85YFR3o6U.flac\n",
            "audio/bal_train/nFkmTa4oY84.flac\n",
            "audio/bal_train/nG5_2IMbBo0.flac\n",
            "audio/bal_train/nGEprNOnCAc.flac\n",
            "audio/bal_train/nFoktpUVeVw.flac\n",
            "audio/bal_train/nGVNmZdFKLw.flac\n",
            "audio/bal_train/nGa9YKv6SCw.flac\n",
            "audio/bal_train/nGmhfmCVnnc.flac\n",
            "audio/bal_train/nGaGQxiL1W4.flac\n",
            "audio/bal_train/nH7Df4PgSLM.flac\n",
            "audio/bal_train/nGnuJJloAPM.flac\n",
            "audio/bal_train/nH0MNGgnj-o.flac\n",
            "audio/bal_train/nHGis4rLffU.flac\n",
            "audio/bal_train/nHnoxtfF5_4.flac\n",
            "audio/bal_train/nIfIAgkB-MI.flac\n",
            "audio/bal_train/nHsPhNQzMsI.flac\n",
            "audio/bal_train/nITNA5-2Dc8.flac\n",
            "audio/bal_train/nJ5VaxlKdQE.flac\n",
            "audio/bal_train/nIHcAyP3ReQ.flac\n",
            "audio/bal_train/nItnCNYFwec.flac\n",
            "audio/bal_train/nJ3tuDmcdTs.flac\n",
            "audio/bal_train/nJGESRc3XfY.flac\n",
            "audio/bal_train/nJ8M89nmQLk.flac\n",
            "audio/bal_train/nJKkJuff4cc.flac\n",
            "audio/bal_train/nJaezskegdc.flac\n",
            "audio/bal_train/nJcdI1CyoBI.flac\n",
            "audio/bal_train/nJnzdZ-KBGs.flac\n",
            "audio/bal_train/nL-4SFTB810.flac\n",
            "audio/bal_train/nLEv1Ww9dEo.flac\n",
            "audio/bal_train/nLT46BqE-OI.flac\n",
            "audio/bal_train/nL4zx0-mi14.flac\n",
            "audio/bal_train/nM0ocSIvM70.flac\n",
            "audio/bal_train/nMfJgnHZ0zc.flac\n",
            "audio/bal_train/nM2ZcgMqhQc.flac\n",
            "audio/bal_train/nNCIu4zbTuU.flac\n",
            "audio/bal_train/nNSPgjtWi60.flac\n",
            "audio/bal_train/nO5g5SWGYdA.flac\n",
            "audio/bal_train/nOAyMCewXEk.flac\n",
            "audio/bal_train/nOEozd3vdpM.flac\n",
            "audio/bal_train/nONXdP6T3pc.flac\n",
            "audio/bal_train/nPXSiWX2Z_4.flac\n",
            "audio/bal_train/nPgdoP5ouO8.flac\n",
            "audio/bal_train/nPwJjECLmEA.flac\n",
            "audio/bal_train/nQyRAHc7uhw.flac\n",
            "audio/bal_train/nQzHU2AR0ao.flac\n",
            "audio/bal_train/nQp7qqTQcF8.flac\n",
            "audio/bal_train/nRzegL8_k7U.flac\n",
            "audio/bal_train/nR-TX29HtDA.flac\n",
            "audio/bal_train/nRqLp_ECINQ.flac\n",
            "audio/bal_train/nSJk6rLC_T4.flac\n",
            "audio/bal_train/nR6vw_k44lg.flac\n",
            "audio/bal_train/nSLxQLYYoNE.flac\n",
            "audio/bal_train/nRy0W3jpk7Q.flac\n",
            "audio/bal_train/nSIskMwIBKg.flac\n",
            "audio/bal_train/nSuNve1KFyg.flac\n",
            "audio/bal_train/nU9FzYOWNJE.flac\n",
            "audio/bal_train/nT1YAP4Vy9s.flac\n",
            "audio/bal_train/nTgne6YEm6o.flac\n",
            "audio/bal_train/nUqq3DhEeZQ.flac\n",
            "audio/bal_train/nUVkuituI7M.flac\n",
            "audio/bal_train/nV3_rChA6RM.flac\n",
            "audio/bal_train/nTt66N7k4Kk.flac\n",
            "audio/bal_train/nW6Naj6eeI4.flac\n",
            "audio/bal_train/nVDRju1OOUY.flac\n",
            "audio/bal_train/nV5jWS1IIM0.flac\n",
            "audio/bal_train/nVSDv46ARvY.flac\n",
            "audio/bal_train/nWhh5mJP-x0.flac\n",
            "audio/bal_train/nWznP9IlpVo.flac\n",
            "audio/bal_train/nXTTbjx_X-8.flac\n",
            "audio/bal_train/nY4tpb8O_Rg.flac\n",
            "audio/bal_train/nX7VVVNcGac.flac\n",
            "audio/bal_train/nXfqAzdu8IY.flac\n",
            "audio/bal_train/nYKBTjSNMv8.flac\n",
            "audio/bal_train/nXYqylS1zpY.flac\n",
            "audio/bal_train/nZLHxu02hhw.flac\n",
            "audio/bal_train/nZ5YXe8yZwI.flac\n",
            "audio/bal_train/nYO8n62Piys.flac\n",
            "audio/bal_train/nZGcya5tpb4.flac\n",
            "audio/bal_train/na2sq-zkPmU.flac\n",
            "audio/bal_train/nZOgoVEud_w.flac\n",
            "audio/bal_train/n_REM0fSVrA.flac\n",
            "audio/bal_train/n_boIyhZqWc.flac\n",
            "audio/bal_train/nagzRHY8eyA.flac\n",
            "audio/bal_train/naVuPZcDEvs.flac\n",
            "audio/bal_train/nZQZ7CpXqAU.flac\n",
            "audio/bal_train/nagRgYmxhx8.flac\n",
            "audio/bal_train/nanSkb7UNmU.flac\n",
            "audio/bal_train/nbB8C-lGSKQ.flac\n",
            "audio/bal_train/nbb8vmfjHJs.flac\n",
            "audio/bal_train/nbcn1howU9U.flac\n",
            "audio/bal_train/ncEthcdxCUg.flac\n",
            "audio/bal_train/nb-qnjlexk4.flac\n",
            "audio/bal_train/ncMDKMEFhnM.flac\n",
            "audio/bal_train/ncWnugwHz_A.flac\n",
            "audio/bal_train/ncmbVqH7rKE.flac\n",
            "audio/bal_train/nck7Z9MtNIU.flac\n",
            "audio/bal_train/ncpGXOMD4G0.flac\n",
            "audio/bal_train/nd4wZwPTf5o.flac\n",
            "audio/bal_train/neLgGXf0XJ4.flac\n",
            "audio/bal_train/ne4IMxs-hMk.flac\n",
            "audio/bal_train/nev-ZegNv44.flac\n",
            "audio/bal_train/nfhsxetUM5Q.flac\n",
            "audio/bal_train/ndayTknUH9o.flac\n",
            "audio/bal_train/ngqJmUB1vsc.flac\n",
            "audio/bal_train/nfGDe975SrY.flac\n",
            "audio/bal_train/ng9Dpk4qiP4.flac\n",
            "audio/bal_train/ng2I7GnYkRA.flac\n",
            "audio/bal_train/nerVxm26Yng.flac\n",
            "audio/bal_train/nfzDCyOzGmE.flac\n",
            "audio/bal_train/ngM-NCk7zAo.flac\n",
            "audio/bal_train/nguwFJDsq4M.flac\n",
            "audio/bal_train/nh0W3YG3SGY.flac\n",
            "audio/bal_train/nhTYKp8lDcc.flac\n",
            "audio/bal_train/nhAismtQmkY.flac\n",
            "audio/bal_train/nhoXQ5DDcbA.flac\n",
            "audio/bal_train/nhoLUwa7wZY.flac\n",
            "audio/bal_train/niIEfj_Ger8.flac\n",
            "audio/bal_train/niJg7Q1XLyU.flac\n",
            "audio/bal_train/nieNjGjjK_I.flac\n",
            "audio/bal_train/niRsK2moX7M.flac\n",
            "audio/bal_train/niLfMd4-7K4.flac\n",
            "audio/bal_train/nix2u7ZyLtA.flac\n",
            "audio/bal_train/nj1YMI_9kNQ.flac\n",
            "audio/bal_train/nj26o5LxaAg.flac\n",
            "audio/bal_train/njE_C33Qj0o.flac\n",
            "audio/bal_train/njCHChY6P9Y.flac\n",
            "audio/bal_train/njXNuSGZnz4.flac\n",
            "audio/bal_train/njYHHWpgIaE.flac\n",
            "audio/bal_train/njTjykvEXzk.flac\n",
            "audio/bal_train/njoiQ9dZ-r4.flac\n",
            "audio/bal_train/nkSRzaqpOCQ.flac\n",
            "audio/bal_train/nlFXRRsM-UE.flac\n",
            "audio/bal_train/njybD3PNrlc.flac\n",
            "audio/bal_train/nkNmUYUjzUI.flac\n",
            "audio/bal_train/nkwIn8eyPmA.flac\n",
            "audio/bal_train/njz6QG61ER0.flac\n",
            "audio/bal_train/nl1UgSOjhVU.flac\n",
            "audio/bal_train/nlWXsfjHeA8.flac\n",
            "audio/bal_train/nkxjWOM2ryw.flac\n",
            "audio/bal_train/nlS05E29D88.flac\n",
            "audio/bal_train/nm5wP76Hrqo.flac\n",
            "audio/bal_train/nl_1JR6WasE.flac\n",
            "audio/bal_train/nlbEKAt5zhY.flac\n",
            "audio/bal_train/nmnGSjIZocU.flac\n",
            "audio/bal_train/nmpM3wpcHD4.flac\n",
            "audio/bal_train/nn2TnOGCHDI.flac\n",
            "audio/bal_train/nn2j42_pUmg.flac\n",
            "audio/bal_train/nn9iLR99iAM.flac\n",
            "audio/bal_train/nn7GU-5f5Ak.flac\n",
            "audio/bal_train/nnKaZpKrcWY.flac\n",
            "audio/bal_train/nnc6m1pBJ4c.flac\n",
            "audio/bal_train/noLrCDzAp5M.flac\n",
            "audio/bal_train/noy0lhzzwOQ.flac\n",
            "audio/bal_train/noYeBRk2XE8.flac\n",
            "audio/bal_train/noeSjikTYuQ.flac\n",
            "audio/bal_train/npbVUyx-TNg.flac\n",
            "audio/bal_train/nr4zrWT3uqc.flac\n",
            "audio/bal_train/nqmGwbxUzlk.flac\n",
            "audio/bal_train/nqcVA89BD6I.flac\n",
            "audio/bal_train/nr9oLIsbDyQ.flac\n",
            "audio/bal_train/nq3vCSHR5hQ.flac\n",
            "audio/bal_train/nrj2zTr7U0o.flac\n",
            "audio/bal_train/nrSXm2jPiAg.flac\n",
            "audio/bal_train/nrpzRwSx03k.flac\n",
            "audio/bal_train/nsxaoH9DjDo.flac\n",
            "audio/bal_train/nsVBasT389w.flac\n",
            "audio/bal_train/nrw3rjiWAbo.flac\n",
            "audio/bal_train/nsc2n5QHnEM.flac\n",
            "audio/bal_train/nsssMnabc0s.flac\n",
            "audio/bal_train/ntCr4ixlFx0.flac\n",
            "audio/bal_train/nte9V6tkTIw.flac\n",
            "audio/bal_train/ntpg9NxWUmQ.flac\n",
            "audio/bal_train/ntulS0PSBZE.flac\n",
            "audio/bal_train/ntzB1zCeVXY.flac\n",
            "audio/bal_train/nurF0VhxtTo.flac\n",
            "audio/bal_train/nu_Bl8Pz6PE.flac\n",
            "audio/bal_train/nuyrbrzYmJg.flac\n",
            "audio/bal_train/nv0TV4MOvxE.flac\n",
            "audio/bal_train/nv0fUg5Y0I0.flac\n",
            "audio/bal_train/nuuykD2akvI.flac\n",
            "audio/bal_train/nv1hWkBbG0g.flac\n",
            "audio/bal_train/nvMEYiJKPQw.flac\n",
            "audio/bal_train/nvPYCEyKgCU.flac\n",
            "audio/bal_train/nvbFwj__frg.flac\n",
            "audio/bal_train/nvRd4xgEWbw.flac\n",
            "audio/bal_train/nvhHpW3zPxU.flac\n",
            "audio/bal_train/nvoGwmKh6NI.flac\n",
            "audio/bal_train/nvrMO6TDu2g.flac\n",
            "audio/bal_train/nwDTH1ggAzM.flac\n",
            "audio/bal_train/nwZC-m2SrUc.flac\n",
            "audio/bal_train/nwMHPaDYg4I.flac\n",
            "audio/bal_train/nwme-nOaYrE.flac\n",
            "audio/bal_train/nwbRz1UP4MI.flac\n",
            "audio/bal_train/nxY70AIQ760.flac\n",
            "audio/bal_train/nxPSJZT5qYU.flac\n",
            "audio/bal_train/nyLpME6YH20.flac\n",
            "audio/bal_train/nyciBuaIZxs.flac\n",
            "audio/bal_train/nyf0IUg4jHE.flac\n",
            "audio/bal_train/nyo33XJBwxA.flac\n",
            "audio/bal_train/o-8WoOD35q0.flac\n",
            "audio/bal_train/nyoCE83Lg-c.flac\n",
            "audio/bal_train/o-aE6HzmgtI.flac\n",
            "audio/bal_train/nzdlPYd8XUs.flac\n",
            "audio/bal_train/o-DsniUGuU4.flac\n",
            "audio/bal_train/o-uOzHZRdYM.flac\n",
            "audio/bal_train/o08dCnpSiAU.flac\n",
            "audio/bal_train/o1E579RL33w.flac\n",
            "audio/bal_train/o0-zzs1GDc4.flac\n",
            "audio/bal_train/o274yH7D0Og.flac\n",
            "audio/bal_train/o28FYkti1eQ.flac\n",
            "audio/bal_train/o2bqT0ZTz7E.flac\n",
            "audio/bal_train/o3OV3Ohbeh4.flac\n",
            "audio/bal_train/o3DFjne7mNA.flac\n",
            "audio/bal_train/o2z2Q4oF4Co.flac\n",
            "audio/bal_train/o3o4dFIoIX4.flac\n",
            "audio/bal_train/o3WBYfLPNyo.flac\n",
            "audio/bal_train/o4OMrBqHTRc.flac\n",
            "audio/bal_train/o4DCUrhSr9U.flac\n",
            "audio/bal_train/o4nz8EPXw8E.flac\n",
            "audio/bal_train/o4eDxGJISqM.flac\n",
            "audio/bal_train/o4qAUSq_bg8.flac\n",
            "audio/bal_train/o5U1bnN0kz8.flac\n",
            "audio/bal_train/o6JRAX5HKgQ.flac\n",
            "audio/bal_train/o6Du9mCBrW0.flac\n",
            "audio/bal_train/o6TUQSPSTYU.flac\n",
            "audio/bal_train/o6N87m5ETxo.flac\n",
            "audio/bal_train/o6Tq9lERFEg.flac\n",
            "audio/bal_train/o6nfEa2ooyY.flac\n",
            "audio/bal_train/o6w_1WIkl6E.flac\n",
            "audio/bal_train/o7QQOJvK2oM.flac\n",
            "audio/bal_train/o76baydsjDU.flac\n",
            "audio/bal_train/o7jBSQRJzuQ.flac\n",
            "audio/bal_train/o7z2je-BVvI.flac\n",
            "audio/bal_train/o7KvzCoet0g.flac\n",
            "audio/bal_train/o8gUvhE-0kA.flac\n",
            "audio/bal_train/o81ZpnAQT9Y.flac\n",
            "audio/bal_train/o8Ods-YRJgs.flac\n",
            "audio/bal_train/o8Q0i9VzQZA.flac\n",
            "audio/bal_train/o8ak7bUSJMc.flac\n",
            "audio/bal_train/o9ReDAzxHvE.flac\n",
            "audio/bal_train/o9VAwBqj0HA.flac\n",
            "audio/bal_train/oAI8RlcZXFw.flac\n",
            "audio/bal_train/o9nKX542J9c.flac\n",
            "audio/bal_train/oANVd7GWDbA.flac\n",
            "audio/bal_train/oAJBkWteljc.flac\n",
            "audio/bal_train/oAOSERlT_Dg.flac\n",
            "audio/bal_train/oARFeTnImOg.flac\n",
            "audio/bal_train/oBBTqXQFTiA.flac\n",
            "audio/bal_train/oBLLs2UcJbQ.flac\n",
            "audio/bal_train/oBg2Df1wiqk.flac\n",
            "audio/bal_train/oBwt8T8P8Zs.flac\n",
            "audio/bal_train/oBzfJ4Hmzi8.flac\n",
            "audio/bal_train/oC0e8GXYy_4.flac\n",
            "audio/bal_train/oD13zrv7sq4.flac\n",
            "audio/bal_train/oD6sKnchJfQ.flac\n",
            "audio/bal_train/oDPtAyu4HTY.flac\n",
            "audio/bal_train/oT3cQK8ySyM.flac\n",
            "audio/bal_train/oTJRivZTMLs.flac\n",
            "audio/bal_train/oTNVYD3UzFs.flac\n",
            "audio/bal_train/oTEXk4wk37k.flac\n",
            "audio/bal_train/oTS4jW77rTQ.flac\n",
            "audio/bal_train/oTNq65oNLPA.flac\n",
            "audio/bal_train/oTzTZqDOIt0.flac\n",
            "audio/bal_train/oUp-acoLyvU.flac\n",
            "audio/bal_train/oUk-fAw3c5M.flac\n",
            "audio/bal_train/oUmRveVMjRs.flac\n",
            "audio/bal_train/oVyvglHg-Ss.flac\n",
            "audio/bal_train/oVtRjiLVf-I.flac\n",
            "audio/bal_train/oWDOOFujd6k.flac\n",
            "audio/bal_train/oXA4wK6JLTk.flac\n",
            "audio/bal_train/oWV6H5WAI-U.flac\n",
            "audio/bal_train/oX-liLQ8bkY.flac\n",
            "audio/bal_train/oXNQ17EMNVA.flac\n",
            "audio/bal_train/oY8jMhTw-wU.flac\n",
            "audio/bal_train/oXXBD36kwuc.flac\n",
            "audio/bal_train/oX_mbAdm7Ws.flac\n",
            "audio/bal_train/oYYFCexBZCU.flac\n",
            "audio/bal_train/oYlN1Ve65yc.flac\n",
            "audio/bal_train/oYk0I5lY9Tg.flac\n",
            "audio/bal_train/oYrRahbeDys.flac\n",
            "audio/bal_train/oYrnNi0n-hk.flac\n",
            "audio/bal_train/oZF73R89bk0.flac\n",
            "audio/bal_train/oZAgHL9zpGM.flac\n",
            "audio/bal_train/oZpq9icGBl4.flac\n",
            "audio/bal_train/oZjG9l_vvOo.flac\n",
            "audio/bal_train/o_l_eCscjSw.flac\n",
            "audio/bal_train/oaRtcfTazFE.flac\n",
            "audio/bal_train/oaWaa5MDLiE.flac\n",
            "audio/bal_train/obGk74Znhbw.flac\n",
            "audio/bal_train/ob8GlVyVSXc.flac\n",
            "audio/bal_train/o_LqYMdKTHM.flac\n",
            "audio/bal_train/obVRHsMY6Yo.flac\n",
            "audio/bal_train/obcIYEMbnIs.flac\n",
            "audio/bal_train/ockKCoOKfmY.flac\n",
            "audio/bal_train/ocCIB2bPq_Y.flac\n",
            "audio/bal_train/ocOYpa4na5k.flac\n",
            "audio/bal_train/od7agrd4aVA.flac\n",
            "audio/bal_train/odl1N1okDJ0.flac\n",
            "audio/bal_train/od5i0WACtIM.flac\n",
            "audio/bal_train/odvyhJNVtRY.flac\n",
            "audio/bal_train/od7-KBOwqAA.flac\n",
            "audio/bal_train/oekK5PiNgSg.flac\n",
            "audio/bal_train/odlZvYN20tc.flac\n",
            "audio/bal_train/oeSyAOMx0ho.flac\n",
            "audio/bal_train/oeWkKfiPQNo.flac\n",
            "audio/bal_train/ofESdVdX-fY.flac\n",
            "audio/bal_train/ofXzCNUYFtc.flac\n",
            "audio/bal_train/ofHhfDm-zBQ.flac\n",
            "audio/bal_train/ofnKFDQl_uw.flac\n",
            "audio/bal_train/ofhH8SvSQMI.flac\n",
            "audio/bal_train/ogG7bajuV7s.flac\n",
            "audio/bal_train/og07vW7R5PI.flac\n",
            "audio/bal_train/ogOTksL2Vas.flac\n",
            "audio/bal_train/ogHTHIYZq80.flac\n",
            "audio/bal_train/ogc8SiYPYyU.flac\n",
            "audio/bal_train/oh0EWEvJI90.flac\n",
            "audio/bal_train/ohIQPsbEQQM.flac\n",
            "audio/bal_train/owic-GeWQco.flac\n",
            "audio/bal_train/ohMaT4TqX7c.flac\n",
            "audio/bal_train/s7sRKH_EdAY.flac\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 685/685 [00:26<00:00, 26.32it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3bc30b2fd244afebb59ec17c2426094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de734d32b95473cb44e4931875b52d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 119/120 [00:33<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-03 23:50:26--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.103, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T235027Z&X-Amz-Expires=3600&X-Amz-Signature=1d19b8fd86b3fdd8eadc539d770fd64d000d5627e18e6e5e65b39eaef564f1bc&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1756947027&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NzAyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=f9AiM3yrfwM%7EOyxQgGAYGrdZE6piBTpMa4l83sysGWqJh7ACc4B2fgbUITEs849%7E6olM6fpx7siPRkdB8FCTVNmnJyFzQ%7EmXqhIlXsSMMXoJVSPT1ByUy724bOi7n7WFBe4wBIw8NqPe9r-kZiykI50yWjDeNKAx69t85nR%7EOowvwQXr3rwZ0KAySHq-3PYkDNp9hYYgQ1CuvREurSAQctQSRvkcpY%7EZJuDh5RaTXyANvX3b0IT78YaXxpu6R4qMheqN5kKPw1yotiv62Q777G3AvgNXOi0HtdpAA-w1qFEo%7EfOUzkRvq-i09MexpQxqo9S6LGTVcKNvLJ9TysKKQw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-03 23:50:27--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/7e1cade4c3fda6a5081158383c8d43c4a3e1e42555150b596b373efddf9b5194?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T235027Z&X-Amz-Expires=3600&X-Amz-Signature=1d19b8fd86b3fdd8eadc539d770fd64d000d5627e18e6e5e65b39eaef564f1bc&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&x-id=GetObject&Expires=1756947027&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NzAyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvN2UxY2FkZTRjM2ZkYTZhNTA4MTE1ODM4M2M4ZDQzYzRhM2UxZTQyNTU1MTUwYjU5NmIzNzNlZmRkZjliNTE5NCoifV19&Signature=f9AiM3yrfwM%7EOyxQgGAYGrdZE6piBTpMa4l83sysGWqJh7ACc4B2fgbUITEs849%7E6olM6fpx7siPRkdB8FCTVNmnJyFzQ%7EmXqhIlXsSMMXoJVSPT1ByUy724bOi7n7WFBe4wBIw8NqPe9r-kZiykI50yWjDeNKAx69t85nR%7EOowvwQXr3rwZ0KAySHq-3PYkDNp9hYYgQ1CuvREurSAQctQSRvkcpY%7EZJuDh5RaTXyANvX3b0IT78YaXxpu6R4qMheqN5kKPw1yotiv62Q777G3AvgNXOi0HtdpAA-w1qFEo%7EfOUzkRvq-i09MexpQxqo9S6LGTVcKNvLJ9TysKKQw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.243.30, 18.238.243.70, 18.238.243.52, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.243.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17280000128 (16G)\n",
            "Saving to: ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’\n",
            "\n",
            "openwakeword_featur 100%[===================>]  16.09G   198MB/s    in 3m 1s   \n",
            "\n",
            "2025-09-03 23:53:27 (91.2 MB/s) - ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’ saved [17280000128/17280000128]\n",
            "\n",
            "--2025-09-03 23:53:27--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.103, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T235328Z&X-Amz-Expires=3600&X-Amz-Signature=4de17956f5c0b1b46a21ff06babef9a21dafdeb9ff2eaf95096e3062e769f450&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1756947208&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NzIwOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=CMJ8es6iKc0y4fhsZB7RSE85m6mUcpx4dZF6usyMXuqFMzVDqRgTe5dbFfRR1fYIDBl4g5-YuB9vsEdOYhtwtyBlozrc6JiUvaAEy8yMUvflNptCZHIHyA5EO97I173EHMLS7zN-DjRvBGEqwhvzHrE2AkN-tGCXH0rdPNGfZCYPxFfJEo5oVsCTTFDXM6H0Chnez7ObkYgwjECPARbUI8IAIpMTHraiS0ENrmAaU1a0v1KURdooZGhg7gct%7Esp1U3jGkgILlG46CRMFcERYcojaXItG7KERWyLGKSyyzgsjEOIjy0YIrEnEGO40CxQpegjdlDtuRFkznOyHWwlF%7EQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-03 23:53:28--  https://cas-bridge.xethub.hf.co/xet-bridge-us/64f3a0b6918ffcc15af6923c/d06b67aa405c24aab66854c32fe850f58387e668e24d58f9c1885d81d86c94cd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250903T235328Z&X-Amz-Expires=3600&X-Amz-Signature=4de17956f5c0b1b46a21ff06babef9a21dafdeb9ff2eaf95096e3062e769f450&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&x-id=GetObject&Expires=1756947208&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1Njk0NzIwOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGYzYTBiNjkxOGZmY2MxNWFmNjkyM2MvZDA2YjY3YWE0MDVjMjRhYWI2Njg1NGMzMmZlODUwZjU4Mzg3ZTY2OGUyNGQ1OGY5YzE4ODVkODFkODZjOTRjZCoifV19&Signature=CMJ8es6iKc0y4fhsZB7RSE85m6mUcpx4dZF6usyMXuqFMzVDqRgTe5dbFfRR1fYIDBl4g5-YuB9vsEdOYhtwtyBlozrc6JiUvaAEy8yMUvflNptCZHIHyA5EO97I173EHMLS7zN-DjRvBGEqwhvzHrE2AkN-tGCXH0rdPNGfZCYPxFfJEo5oVsCTTFDXM6H0Chnez7ObkYgwjECPARbUI8IAIpMTHraiS0ENrmAaU1a0v1KURdooZGhg7gct%7Esp1U3jGkgILlG46CRMFcERYcojaXItG7KERWyLGKSyyzgsjEOIjy0YIrEnEGO40CxQpegjdlDtuRFkznOyHWwlF%7EQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.243.52, 18.238.243.58, 18.238.243.70, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.243.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184836608 (176M)\n",
            "Saving to: ‘validation_set_features.npy’\n",
            "\n",
            "validation_set_feat 100%[===================>] 176.27M   276MB/s    in 0.6s    \n",
            "\n",
            "2025-09-03 23:53:28 (276 MB/s) - ‘validation_set_features.npy’ saved [184836608/184836608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @markdown # 3. Train the Model\n",
        "# @markdown Now that you have verified your target wake word and downloaded the data,\n",
        "# @markdown the last step is to adjust the training paramaters (or keep\n",
        "# @markdown the defaults below) and start the training!\n",
        "\n",
        "# @markdown Each paramater controls a different aspect of training:\n",
        "# @markdown - `number_of_examples` controls how many examples of your wakeword\n",
        "# @markdown are generated. The default (1,000) usually produces a good model,\n",
        "# @markdown but between 30,000 and 50,000 is often the best.\n",
        "\n",
        "# @markdown - `number_of_training_steps` controls how long to train the model.\n",
        "# @markdown Similar to the number of examples, the default (10,000) usually works well\n",
        "# @markdown but training longer usually helps.\n",
        "\n",
        "# @markdown - `false_activation_penalty` controls how strongly false activations\n",
        "# @markdown are penalized during the training process. Higher values can make the model\n",
        "# @markdown much less likely to activate when it shouldn't, but may also cause it\n",
        "# @markdown to not activate when the wake word isn't spoken clearly and there is\n",
        "# @markdown background noise.\n",
        "\n",
        "# @markdown With the default values shown below,\n",
        "# @markdown this takes about 30 - 60 minutes total on the normal CPU Colab runtime.\n",
        "# @markdown If you want to train on more examples or train for longer,\n",
        "# @markdown try changing the runtime type to a GPU to significantly speedup\n",
        "# @markdown the example generating and model training.\n",
        "\n",
        "# @markdown When the model finishes training, you can navigate to the `my_custom_model` folder\n",
        "# @markdown in the file browser on the left (click on the folder icon), and download\n",
        "# @markdown the [your target wake word].onnx or  <your target wake word>.tflite files.\n",
        "# @markdown You can then use these as you would any other openWakeWord model!\n",
        "\n",
        "# Load default YAML config file for training\n",
        "import yaml\n",
        "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
        "\n",
        "# Modify values in the config and save a new version\n",
        "number_of_examples = 1000 # @param {type:\"slider\", min:100, max:50000, step:50}\n",
        "number_of_training_steps = 10000  # @param {type:\"slider\", min:0, max:50000, step:100}\n",
        "false_activation_penalty = 1500  # @param {type:\"slider\", min:100, max:5000, step:50}\n",
        "config[\"target_phrase\"] = [target_word]\n",
        "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
        "config[\"n_samples\"] = number_of_examples\n",
        "config[\"n_samples_val\"] = max(500, number_of_examples//10)\n",
        "config[\"steps\"] = number_of_training_steps\n",
        "config[\"target_accuracy\"] = 0.5\n",
        "config[\"target_recall\"] = 0.25\n",
        "config[\"output_dir\"] = \"./my_custom_model\"\n",
        "config[\"max_negative_weight\"] = false_activation_penalty\n",
        "\n",
        "config[\"background_paths\"] = ['./audioset_16k', './fma']  # multiple background datasets are supported\n",
        "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "with open('my_model.yaml', 'w') as file:\n",
        "    documents = yaml.dump(config, file)\n",
        "\n",
        "# Generate clips\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --generate_clips\n",
        "\n",
        "# Step 2: Augment the generated clips\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips\n",
        "\n",
        "# Step 3: Train model\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model\n",
        "\n",
        "# # Manually save to tflite as this doesn't work right in colab (broken in python 3.11, default in Colab as of January 2025)\n",
        "# def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "#     \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "#     # imports\n",
        "#     import onnx\n",
        "#     import logging\n",
        "#     import tempfile\n",
        "#     from onnx_tf.backend import prepare\n",
        "#     import tensorflow as tf\n",
        "\n",
        "#     # Convert to tflite from onnx model\n",
        "#     onnx_model = onnx.load(onnx_model_path)\n",
        "#     tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "#     with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "#         tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "#         converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "#         tflite_model = converter.convert()\n",
        "\n",
        "#         logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
        "#         with open(output_path, 'wb') as f:\n",
        "#             f.write(tflite_model)\n",
        "\n",
        "#     return None\n",
        "\n",
        "# convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n",
        "\n",
        "# Convert ONNX model to tflite using `onnx2tf` library (works for python 3.11 as of January 2025)\n",
        "onnx_model_path = f\"my_custom_model/{config['model_name']}.onnx\"\n",
        "name1, name2 = f\"my_custom_model/{config['model_name']}_float32.tflite\", f\"my_custom_model/{config['model_name']}.tflite\"\n",
        "!onnx2tf -i {onnx_model_path} -o my_custom_model/ -kat onnx____Flatten_0\n",
        "!mv {name1} {name2}\n",
        "\n",
        "# Automatically download the trained model files\n",
        "from google.colab import files\n",
        "\n",
        "files.download(f\"my_custom_model/{config['model_name']}.onnx\")\n",
        "files.download(f\"my_custom_model/{config['model_name']}.tflite\")\n"
      ],
      "metadata": {
        "id": "qgaKWIY6WlJ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef36ae89-c117-42a1-98d0-09dc445116c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-03 23:58:04.719198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756943885.050756   11180 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756943885.140665   11180 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756943885.814696   11180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756943885.814749   11180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756943885.814754   11180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756943885.814758   11180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-03 23:58:05.886734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "/content/piper-sample-generator/generate_samples.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch_model = torch.load(model_path)\n",
            "WARNING:root:Downloading phonemizer model from DeepPhonemizer library...\n",
            "/usr/local/lib/python3.12/dist-packages/dp/model/model.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "WARNING:root:The word 'khum_puter' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
            "WARNING:root:Phones for 'khum_puter': [K][AH][M][P][Y][UW][T][ER]\n",
            "WARNING:root:The word 'khum_puter' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
            "WARNING:root:Phones for 'khum_puter': [K][AH][M][P][Y][UW][T][ER]\n",
            "2025-09-04 00:15:59.789385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756944959.823827   15494 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756944959.831875   15494 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756944959.854039   15494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756944959.854090   15494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756944959.854094   15494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756944959.854098   15494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 00:15:59.860475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = PitchShift(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = BandStopFilter(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddColoredNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddBackgroundNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Gain(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Compose(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
            "  warnings.warn(\n",
            "Computing features: 100% 62/62 [01:45<00:00,  1.71s/it]\n",
            "Trimming empty rows: 1it [00:00, 36.98it/s]\n",
            "Computing features: 100% 62/62 [01:36<00:00,  1.56s/it]\n",
            "Trimming empty rows: 1it [00:00, 30.90it/s]\n",
            "Computing features: 100% 31/31 [00:52<00:00,  1.69s/it]\n",
            "Trimming empty rows: 1it [00:00, 50.47it/s]\n",
            "Computing features: 100% 31/31 [00:58<00:00,  1.87s/it]\n",
            "Trimming empty rows: 1it [00:00, 60.83it/s]\n",
            "2025-09-04 00:21:38.024985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756945298.051323   18372 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756945298.058876   18372 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756945298.079130   18372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756945298.079180   18372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756945298.079185   18372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756945298.079189   18372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 00:21:38.085115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "Training: 100% 9999/10000 [08:08<00:00, 20.46it/s]\n",
            "Training: 100% 999/1000.0 [03:43<00:00,  4.47it/s]\n",
            "Training: 100% 999/1000.0 [03:34<00:00,  4.66it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/openwakeword/openwakeword/train.py\", line 901, in <module>\n",
            "    convert_onnx_to_tflite(os.path.join(config[\"output_dir\"], config[\"model_name\"] + \".onnx\"),\n",
            "  File \"/content/openwakeword/openwakeword/train.py\", line 578, in convert_onnx_to_tflite\n",
            "    from onnx_tf.backend import prepare\n",
            "ModuleNotFoundError: No module named 'onnx_tf'\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756946254.824423   22221 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756946254.835825   22221 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756946254.878444   22221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756946254.878501   22221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756946254.878508   22221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756946254.878512   22221 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add        │ 4              │ 4                │\n",
            "│ Constant   │ 14             │ 12               │\n",
            "│ Div        │ 2              │ 2                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 3              │ 3                │\n",
            "│ Mul        │ 2              │ 2                │\n",
            "│ Pow        │ 2              │ 2                │\n",
            "│ ReduceMean │ 4              │ 4                │\n",
            "│ Relu       │ 2              │ 2                │\n",
            "│ Sigmoid    │ 1              │ 1                │\n",
            "│ Sqrt       │ 2              │ 2                │\n",
            "│ Sub        │ 2              │ 2                │\n",
            "│ Model Size │ 200.6KiB       │ 201.4KiB         │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add        │ 4              │ 4                │\n",
            "│ Constant   │ 12             │ 12               │\n",
            "│ Div        │ 2              │ 2                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 3              │ 3                │\n",
            "│ Mul        │ 2              │ 2                │\n",
            "│ Pow        │ 2              │ 2                │\n",
            "│ ReduceMean │ 4              │ 4                │\n",
            "│ Relu       │ 2              │ 2                │\n",
            "│ Sigmoid    │ 1              │ 1                │\n",
            "│ Sqrt       │ 2              │ 2                │\n",
            "│ Sub        │ 2              │ 2                │\n",
            "│ Model Size │ 201.4KiB       │ 201.4KiB         │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add        │ 4              │ 4                │\n",
            "│ Constant   │ 12             │ 12               │\n",
            "│ Div        │ 2              │ 2                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 3              │ 3                │\n",
            "│ Mul        │ 2              │ 2                │\n",
            "│ Pow        │ 2              │ 2                │\n",
            "│ ReduceMean │ 4              │ 4                │\n",
            "│ Relu       │ 2              │ 2                │\n",
            "│ Sigmoid    │ 1              │ 1                │\n",
            "│ Sqrt       │ 2              │ 2                │\n",
            "│ Sub        │ 2              │ 2                │\n",
            "│ Model Size │ 201.4KiB       │ 201.4KiB         │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "\u001b[32mModel optimizing complete!\u001b[0m\n",
            "\n",
            "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
            "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
            "\n",
            "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
            "\n",
            "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: onnx____Flatten_0 \u001b[32mshape\u001b[0m: [1, 16, 96] \u001b[32mdtype\u001b[0m: float32\n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Flatten\u001b[35m onnx_op_name\u001b[0m: /flatten/Flatten\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: onnx____Flatten_0 \u001b[36mshape\u001b[0m: [1, 16, 96] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /flatten/Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 1536] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: onnx____Flatten_0 \u001b[34mshape\u001b[0m: (1, 16, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 1536] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (1, 1536) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /layer1/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /flatten/Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 1536] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: layer1.weight \u001b[36mshape\u001b[0m: [32, 1536] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: layer1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layer1/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 1536) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1536, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMean\u001b[35m onnx_op_name\u001b[0m: /layernorm1/ReduceMean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layer1/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/ReduceMean_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sub\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Sub\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layer1/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/ReduceMean_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: subtract\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pow\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Pow\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Pow_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pow\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_4/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMean\u001b[35m onnx_op_name\u001b[0m: /layernorm1/ReduceMean_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Pow_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/ReduceMean_1_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_4/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/ReduceMean_1_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sqrt\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Sqrt\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Sqrt_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sqrt\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt/Sqrt:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Div\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Div\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/Sqrt_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Div_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: divide\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt/Sqrt:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide/truediv:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Div_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: layernorm1.weight \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide/truediv:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_10/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /layernorm1/Add_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: layernorm1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /layernorm1/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_10/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /relu1/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /layernorm1/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /relu1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /blocks.0/fcn_layer/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /relu1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: blocks.0.fcn_layer.weight \u001b[36mshape\u001b[0m: [32, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: blocks.0.fcn_layer.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/fcn_layer/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMean\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/ReduceMean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/fcn_layer/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/ReduceMean_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sub\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Sub\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/fcn_layer/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /blocks.0/layer_norm/ReduceMean_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: subtract\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_1/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pow\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Pow\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Pow_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pow\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_1/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_16/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMean\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/ReduceMean_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Pow_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/ReduceMean_1_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_16/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/ReduceMean_1_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /layernorm1/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Add_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sqrt\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Sqrt\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Add_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Sqrt_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sqrt\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt_1/Sqrt:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Div\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Div\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /blocks.0/layer_norm/Sqrt_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Div_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: divide\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract_1/Sub:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt_1/Sqrt:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide_1/truediv:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Mul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Div_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: blocks.0.layer_norm.weight \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide_1/truediv:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_22/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /blocks.0/layer_norm/Add_1\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: blocks.0.layer_norm.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/layer_norm/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_22/Mul:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /blocks.0/relu/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/layer_norm/Add_1_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /blocks.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /last_layer/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /blocks.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: last_layer.weight \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: last_layer.bias \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /last_layer/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (32, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 26\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: /last_act/Sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /last_layer/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 39 \u001b[36mshape\u001b[0m: [1, 1] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
            "Saved artifact at 'my_custom_model/'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 16, 96), dtype=tf.float32, name='onnx____Flatten_0')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132920077135568: TensorSpec(shape=(1536, 32), dtype=tf.float32, name=None)\n",
            "  132920077136336: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  132920077137296: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  132920077138448: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  132920077137680: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)\n",
            "  132920077137488: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)\n",
            "  132920077137872: TensorSpec(shape=(32, 32), dtype=tf.float32, name=None)\n",
            "  132920077135952: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  132920077139600: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  132920077133072: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  132920032887440: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)\n",
            "  132920032887632: TensorSpec(shape=(1, 32), dtype=tf.float32, name=None)\n",
            "  132920032887056: TensorSpec(shape=(32, 1), dtype=tf.float32, name=None)\n",
            "  132920077136528: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  132920032887248: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "\u001b[32msaved_model output complete!\u001b[0m\n",
            "I0000 00:00:1756946266.277794   22221 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1756946266.280139   22221 single_machine.cc:374] Starting new session\n",
            "W0000 00:00:1756946266.452959   22221 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1756946266.453018   22221 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
            "I0000 00:00:1756946266.952118   22221 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1756946266.952310   22221 single_machine.cc:374] Starting new session\n",
            "W0000 00:00:1756946267.010939   22221 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1756946267.010982   22221 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8dddb23a-11ef-4665-9c13-3e7c1bc371be\", \"khum_puter.onnx\", 206292)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b738a141-5c8d-45a5-8c13-7572f63eed87\", \"khum_puter.tflite\", 206976)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}